{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "072dec61",
   "metadata": {},
   "source": [
    "# Mielstone 2"
   ]
  },
 
  {
   "cell_type": "markdown",
   "id": "06763e3f",
   "metadata": {},
   "source": [
    "## Video Link & Samples\n",
    "https://drive.google.com/drive/folders/1NyixRXYeqys-zsf9zgNGbhpxO6PX9BzP?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8371f2d",
   "metadata": {},
   "source": [
    "## Problem Definition\n",
    "\n",
    "Detecting, Tracking and segmenting vehicles is an important and emerging research area for intelligent transportation systems. Image processing plays an important role in detecting vehicles from a traffic surveillance videos. \n",
    "Traffic monitoring through image processing leads to better control of flow of traffic as well as to identify reckless users and speed violators.\n",
    "Counting those detected vehicles also will come in handy when forecasting traffic jams and road congestions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c43d32",
   "metadata": {},
   "source": [
    "## Algorithm \n",
    "- In this project we YOLO which is a real time object detection algorithm and can detect and classify multiple objects in same frame, it does that by dividing the image into NxN Grids and each grid is sent to the model and given a certain probabiliity, the class with the maximum probability is chosen\n",
    "- The confiuguration and weights of the YOLO network is fount online because it can be pretty chellenging to train so we use those files \n",
    "- We Use the DNN module from cv2 to work with YOLO directly via the two files already mentioned\n",
    "- The program is divided into two parts, the first one is the tracker for vehicle detection using the OpenCv and the second part is the main detection program"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1661e6d7",
   "metadata": {},
   "source": [
    "## Steps\n",
    "\n",
    "##### 1. We pre-process the image or video and feed forward those frames to the network\n",
    "##### 2. Then comes the Custom-Made Post process Function\n",
    "  ###### 2.1.  We define an empty list and using two for loops we iterate through each vector to collect confidence score and classID index\n",
    "  ###### 2.2. We check if the class confidence scor is greater than our defined confThreshold\n",
    "  ###### 2.3. Using NMSBoxes() Method we reduce the number of boxes and take the best detection  \n",
    "  ###### 2.4. Draw bounding box\n",
    "  ###### 2.5. Call Frequency counter to keep track of number of vehicles\n",
    "###### 3. Final part will be Showing the post processed image on screen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a3ec02",
   "metadata": {},
   "source": [
    "## Links of Weight, Cfg, names files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6571c818",
   "metadata": {},
   "source": [
    "### Because These files are of high sizes here is the link for downloading them \n",
    "- yolov3-320.cfg\n",
    "- yolov3-320.weights\n",
    "- coco.names\n",
    "- https://pjreddie.com/darknet/yolo/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0419b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Necessary packages\n",
    "import math\n",
    "import cv2\n",
    "import csv\n",
    "import collections\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1575dac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class EuclideanDistTracker:\n",
    "    def __init__(self):\n",
    "        # Store the center positions of the objects\n",
    "        self.center_points = {}\n",
    "        # Keep the count of the IDs\n",
    "        # each time a new object id detected, the count will increase by one\n",
    "        self.id_count = 0\n",
    "\n",
    "\n",
    "    def update(self, objects_rect):\n",
    "        # Objects boxes and ids\n",
    "        objects_bbs_ids = []\n",
    "\n",
    "        # Get center point of new object\n",
    "        for rect in objects_rect:\n",
    "            x, y, w, h, index = rect\n",
    "            cx = (x + x + w) // 2\n",
    "            cy = (y + y + h) // 2\n",
    "\n",
    "            # Find out if that object was detected already\n",
    "            same_object_detected = False\n",
    "            for id, pt in self.center_points.items():\n",
    "                dist = math.hypot(cx - pt[0], cy - pt[1])\n",
    "\n",
    "                if dist < 25:\n",
    "                    self.center_points[id] = (cx, cy)\n",
    "                    # print(self.center_points)\n",
    "                    objects_bbs_ids.append([x, y, w, h, id, index])\n",
    "                    same_object_detected = True\n",
    "                    break\n",
    "\n",
    "            # New object is detected we assign the ID to that object\n",
    "            if same_object_detected is False:\n",
    "                self.center_points[self.id_count] = (cx, cy)\n",
    "                objects_bbs_ids.append([x, y, w, h, self.id_count, index])\n",
    "                self.id_count += 1\n",
    "\n",
    "        # Clean the dictionary by center points to remove IDS not used anymore\n",
    "        new_center_points = {}\n",
    "        for obj_bb_id in objects_bbs_ids:\n",
    "            _, _, _, _, object_id, index = obj_bb_id\n",
    "            center = self.center_points[object_id]\n",
    "            new_center_points[object_id] = center\n",
    "\n",
    "        # Update dictionary with IDs not used removed\n",
    "        self.center_points = new_center_points.copy()\n",
    "        return objects_bbs_ids\n",
    "\n",
    "\n",
    "\n",
    "def ad(a, b):\n",
    "    return a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d09d538a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for finding the center of a rectangle\n",
    "def find_center(x, y, w, h):\n",
    "    x1=int(w/2)\n",
    "    y1=int(h/2)\n",
    "    cx = x+x1\n",
    "    cy=y+y1\n",
    "    return cx, cy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edd67ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for finding the detected objects from the network output\n",
    "def postProcess(outputs,img):\n",
    "    global detected_classNames\n",
    "    height, width = img.shape[:2]\n",
    "    boxes = []\n",
    "    classIds = []\n",
    "    confidence_scores = []\n",
    "    detection = []\n",
    "    for output in outputs:\n",
    "        for det in output:\n",
    "            scores = det[5:]\n",
    "            classId = np.argmax(scores)\n",
    "            confidence = scores[classId]\n",
    "            if classId in required_class_index:\n",
    "                if confidence > confThreshold:\n",
    "                    # print(classId)\n",
    "                    w,h = int(det[2]*width) , int(det[3]*height)\n",
    "                    x,y = int((det[0]*width)-w/2) , int((det[1]*height)-h/2)\n",
    "                    boxes.append([x,y,w,h])\n",
    "                    classIds.append(classId)\n",
    "                    confidence_scores.append(float(confidence))\n",
    "\n",
    "    # Apply Non-Max Suppression\n",
    "    indices = cv2.dnn.NMSBoxes(boxes, confidence_scores, confThreshold, nmsThreshold)\n",
    "    # print(classIds)\n",
    "    for i in indices.flatten():\n",
    "        x, y, w, h = boxes[i][0], boxes[i][1], boxes[i][2], boxes[i][3]\n",
    "        # print(x,y,w,h)\n",
    "\n",
    "        color = [int(c) for c in colors[classIds[i]]]\n",
    "        name = classNames[classIds[i]]\n",
    "        detected_classNames.append(name)\n",
    "        # Draw classname and confidence score \n",
    "        cv2.putText(img,f'{name.upper()} {int(confidence_scores[i]*100)}%',\n",
    "                  (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)\n",
    "\n",
    "        # Draw bounding rectangle\n",
    "        cv2.rectangle(img, (x, y), (x + w, y + h), color, 1)\n",
    "        detection.append([x, y, w, h, required_class_index.index(classIds[i])])\n",
    "\n",
    "    # Update the tracker for each object\n",
    "    boxes_ids = tracker.update(detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "623b2b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One of the main functions in the project, this function can be called\n",
    "# to apply detection and counting using a video locally on the machine\n",
    "\n",
    "def realTime():\n",
    "    while True:\n",
    "        success, img = cap.read()\n",
    "        img = cv2.resize(img, (608,608), interpolation = cv2.INTER_AREA)\n",
    "        #img = cv2.resize(img,(0,0),None,0.5,0.5)\n",
    "        ih, iw, channels = img.shape\n",
    "        #blob = cv2.dnn.blobFromImage(img, 1 / 255, (input_size, input_size), [0, 0, 0], 1, crop=False)\n",
    "        blob = cv2.dnn.blobFromImage(img, 1 / 255, (608 , 608), [0, 0, 0], 1, crop=False)\n",
    "\n",
    "        # Set the input of the network\n",
    "        net.setInput(blob)\n",
    "        layersNames = net.getLayerNames()\n",
    "        outputNames = [(layersNames[i- 1]) for i in net.getUnconnectedOutLayers()]\n",
    "        # Feed data to the network\n",
    "        outputs = net.forward(outputNames)\n",
    "    \n",
    "        # Find the objects from the network output\n",
    "        postProcess(outputs,img)\n",
    "        frequency = collections.Counter(detected_classNames)\n",
    "        del detected_classNames[:]\n",
    "        \n",
    "        cv2.putText(img, \"Car:        \"+str(frequency['car']), (20, 40), cv2.FONT_HERSHEY_SIMPLEX, font_size, font_color, font_thickness)\n",
    "        cv2.putText(img, \"Motorbike:  \"+str(frequency['motorbike']), (20, 60), cv2.FONT_HERSHEY_SIMPLEX, font_size, font_color, font_thickness)\n",
    "        cv2.putText(img, \"Bus:        \"+str(frequency['bus']), (20, 80), cv2.FONT_HERSHEY_SIMPLEX, font_size, font_color, font_thickness)\n",
    "        cv2.putText(img, \"Truck:      \"+str(frequency['truck']), (20, 100), cv2.FONT_HERSHEY_SIMPLEX, font_size, font_color, font_thickness)\n",
    "        \n",
    "\n",
    "        # Show the frames\n",
    "        cv2.imshow('Output', img)\n",
    "\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Write the vehicle counting information in a file and save it\n",
    "\n",
    "    # Finally realese the capture object and destroy all active windows\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c191deb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_static_image(image):\n",
    "    img = cv2.imread(image)\n",
    "    img = cv2.resize(img, (608,608), interpolation = cv2.INTER_AREA)\n",
    "    blob = cv2.dnn.blobFromImage(img, 1 / 255, (608 , 608), [0, 0, 0], 1, crop=False)\n",
    "\n",
    "    # Set the input of the network\n",
    "    net.setInput(blob)\n",
    "    layersNames = net.getLayerNames()\n",
    "    outputNames = [(layersNames[i- 1]) for i in net.getUnconnectedOutLayers()]\n",
    "    # Feed data to the network\n",
    "    outputs = net.forward(outputNames)\n",
    "\n",
    "    # Find the objects from the network output\n",
    "    postProcess(outputs,img)\n",
    "\n",
    "    # count the frequency of detected classes\n",
    "    frequency = collections.Counter(detected_classNames)\n",
    "    del detected_classNames[:]\n",
    "    print(frequency)\n",
    "    # Draw counting texts in the frame\n",
    "    cv2.putText(img, \"Car:        \"+str(frequency['car']), (20, 40), cv2.FONT_HERSHEY_SIMPLEX, font_size, font_color, font_thickness)\n",
    "    cv2.putText(img, \"Motorbike:  \"+str(frequency['motorbike']), (20, 60), cv2.FONT_HERSHEY_SIMPLEX, font_size, font_color, font_thickness)\n",
    "    cv2.putText(img, \"Bus:        \"+str(frequency['bus']), (20, 80), cv2.FONT_HERSHEY_SIMPLEX, font_size, font_color, font_thickness)\n",
    "    cv2.putText(img, \"Truck:      \"+str(frequency['truck']), (20, 100), cv2.FONT_HERSHEY_SIMPLEX, font_size, font_color, font_thickness)\n",
    "\n",
    "\n",
    "    cv2.imshow(\"image\", img)\n",
    "\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "212f179e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['person', 'bicycle', 'car', 'motorbike', 'aeroplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'sofa', 'pottedplant', 'bed', 'diningtable', 'toilet', 'tvmonitor', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n",
      "80\n"
     ]
    }
   ],
   "source": [
    "# Initialize Tracker\n",
    "# The tracker basically uses euclidean distance between two points in current and previous\n",
    "# frame and if the distance is less than threshold it confirms that it is the same object\n",
    "tracker = EuclideanDistTracker()\n",
    "\n",
    "# Initialize the videocapture object\n",
    "cap = cv2.VideoCapture('Traffic_video.mp4')\n",
    "input_size = 320\n",
    "\n",
    "#Initialize The image you want to do detection and counting on\n",
    "image_file = 'Traffic_snap.jpg'\n",
    "\n",
    "# Detection confidence threshold\n",
    "confThreshold = 0.2\n",
    "nmsThreshold  = 0.2\n",
    "\n",
    "font_color = (0, 0, 255)\n",
    "font_size = 0.5\n",
    "font_thickness = 2\n",
    "\n",
    "\n",
    "# Store Coco Names in a list\n",
    "classesFile = \"coco.names\"\n",
    "classNames = open(classesFile).read().strip().split('\\n')\n",
    "print(classNames)\n",
    "print(len(classNames))\n",
    "\n",
    "# class index for our required detection classes\n",
    "required_class_index = [2, 3, 5, 7]\n",
    "\n",
    "detected_classNames = []\n",
    "\n",
    "## Model Files\n",
    "modelConfiguration = 'yolov3-320.cfg'\n",
    "modelWeigheights = 'yolov3-320.weights'\n",
    "\n",
    "# configure the network model\n",
    "net = cv2.dnn.readNetFromDarknet(modelConfiguration, modelWeigheights)\n",
    "\n",
    "# Configure the network backend to work on GPU\n",
    "\n",
    "net.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)\n",
    "net.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)\n",
    "\n",
    "# Define random colour for each class\n",
    "np.random.seed(42)\n",
    "colors = np.random.randint(0, 255, size=(len(classNames), 3), dtype='uint8')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "84cb6d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    realTime()\n",
    "    #from_static_image(image_file)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
